{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis and Machine Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7tynHZPSlBM"
      },
      "source": [
        "# **Text** **Data** **Vectorization** \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0rPcIxDSmTk"
      },
      "source": [
        "# import\r\n",
        "\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "import pandas as pd\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05FgMpcp1r9H"
      },
      "source": [
        "text = [\"Paul likes to watch movies. Mary likes movies too.\",\n",
        "        \"Paul also likes to watch football games\",\n",
        "        \"Paul likes to watch movies. Mary likes movies too. Mary also likes to watch football games.\" \n",
        "        ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUPN1sFs5YMS"
      },
      "source": [
        "**CountVectorizer Unigrams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J576WmLpV_3Q"
      },
      "source": [
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N02LFaZrWI1b"
      },
      "source": [
        "X = vectorizer.fit_transform(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aArLZlOWMI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa1f9568-a67a-4b82-8690-ca62d1df33e0"
      },
      "source": [
        "#X.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 2, 1, 2, 1, 1, 1, 1],\n",
              "       [1, 1, 1, 1, 0, 0, 1, 1, 0, 1],\n",
              "       [1, 1, 1, 3, 2, 2, 1, 2, 1, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7bg1qx_WkhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50430c36-52c8-4461-8099-21c7cd358ec0"
      },
      "source": [
        "vectorizer.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['also',\n",
              " 'football',\n",
              " 'games',\n",
              " 'likes',\n",
              " 'mary',\n",
              " 'movies',\n",
              " 'paul',\n",
              " 'to',\n",
              " 'too',\n",
              " 'watch']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLjsWLTxXEm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b109c28-0595-4cfb-8266-f1a4492982a7"
      },
      "source": [
        "vectorizer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'also': 0,\n",
              " 'football': 1,\n",
              " 'games': 2,\n",
              " 'likes': 3,\n",
              " 'mary': 4,\n",
              " 'movies': 5,\n",
              " 'paul': 6,\n",
              " 'to': 7,\n",
              " 'too': 8,\n",
              " 'watch': 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vol7VBA9XZba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "6585c4b2-d647-4a3e-861c-00ad68688ba2"
      },
      "source": [
        "pd.DataFrame(X.toarray(),index=text,columns=vectorizer.get_feature_names())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>also</th>\n",
              "      <th>football</th>\n",
              "      <th>games</th>\n",
              "      <th>likes</th>\n",
              "      <th>mary</th>\n",
              "      <th>movies</th>\n",
              "      <th>paul</th>\n",
              "      <th>to</th>\n",
              "      <th>too</th>\n",
              "      <th>watch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Paul likes to watch movies. Mary likes movies too.</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paul also likes to watch football games</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paul likes to watch movies. Mary likes movies too. Mary also likes to watch football games.</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    also  football  ...  too  watch\n",
              "Paul likes to watch movies. Mary likes movies too.     0         0  ...    1      1\n",
              "Paul also likes to watch football games                1         1  ...    0      1\n",
              "Paul likes to watch movies. Mary likes movies t...     1         1  ...    1      2\n",
              "\n",
              "[3 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEcHDwfR5rCE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmrZZvfo5mtZ"
      },
      "source": [
        "**CountVectorizer Bi-grams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6jhhdUq0OAk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "0361b4fd-10d7-41cb-d941-857d2db9e6fc"
      },
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
        "X = vectorizer.fit_transform(text)\n",
        "pd.DataFrame(X.toarray(),index=text,columns=vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>also likes</th>\n",
              "      <th>football games</th>\n",
              "      <th>likes movies</th>\n",
              "      <th>likes to</th>\n",
              "      <th>mary also</th>\n",
              "      <th>mary likes</th>\n",
              "      <th>movies mary</th>\n",
              "      <th>movies too</th>\n",
              "      <th>paul also</th>\n",
              "      <th>paul likes</th>\n",
              "      <th>to watch</th>\n",
              "      <th>too mary</th>\n",
              "      <th>watch football</th>\n",
              "      <th>watch movies</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Paul likes to watch movies. Mary likes movies too.</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paul also likes to watch football games</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paul likes to watch movies. Mary likes movies too. Mary also likes to watch football games.</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    also likes  ...  watch movies\n",
              "Paul likes to watch movies. Mary likes movies too.           0  ...             1\n",
              "Paul also likes to watch football games                      1  ...             0\n",
              "Paul likes to watch movies. Mary likes movies t...           1  ...             1\n",
              "\n",
              "[3 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX4z1GEJ0RpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebffd7a9-5c4e-4bae-f3d8-36e4b10ee8e3"
      },
      "source": [
        "vectorizer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'also likes': 0,\n",
              " 'football games': 1,\n",
              " 'likes movies': 2,\n",
              " 'likes to': 3,\n",
              " 'mary also': 4,\n",
              " 'mary likes': 5,\n",
              " 'movies mary': 6,\n",
              " 'movies too': 7,\n",
              " 'paul also': 8,\n",
              " 'paul likes': 9,\n",
              " 'to watch': 10,\n",
              " 'too mary': 11,\n",
              " 'watch football': 12,\n",
              " 'watch movies': 13}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8U6yVj2VqZQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hVZlIMK51ei"
      },
      "source": [
        "**CountVectorizer Tri-grams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFUkAEsm1Oa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "outputId": "13688002-8c4a-461a-a02c-c642636bdea5"
      },
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(3,3))\n",
        "X = vectorizer.fit_transform(text)\n",
        "pd.DataFrame(X.toarray(),index=text,columns=vectorizer.get_feature_names())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>also likes to</th>\n",
              "      <th>likes movies too</th>\n",
              "      <th>likes to watch</th>\n",
              "      <th>mary also likes</th>\n",
              "      <th>mary likes movies</th>\n",
              "      <th>movies mary likes</th>\n",
              "      <th>movies too mary</th>\n",
              "      <th>paul also likes</th>\n",
              "      <th>paul likes to</th>\n",
              "      <th>to watch football</th>\n",
              "      <th>to watch movies</th>\n",
              "      <th>too mary also</th>\n",
              "      <th>watch football games</th>\n",
              "      <th>watch movies mary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Paul likes to watch movies. Mary likes movies too.</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paul also likes to watch football games</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paul likes to watch movies. Mary likes movies too. Mary also likes to watch football games.</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    also likes to  ...  watch movies mary\n",
              "Paul likes to watch movies. Mary likes movies too.              0  ...                  1\n",
              "Paul also likes to watch football games                         1  ...                  0\n",
              "Paul likes to watch movies. Mary likes movies t...              1  ...                  1\n",
              "\n",
              "[3 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G29QM3UwV9KI",
        "outputId": "8848a2c8-7986-497b-9d9f-7d889809289f"
      },
      "source": [
        "vectorizer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'also likes to': 0,\n",
              " 'likes movies too': 1,\n",
              " 'likes to watch': 2,\n",
              " 'mary also likes': 3,\n",
              " 'mary likes movies': 4,\n",
              " 'movies mary likes': 5,\n",
              " 'movies too mary': 6,\n",
              " 'paul also likes': 7,\n",
              " 'paul likes to': 8,\n",
              " 'to watch football': 9,\n",
              " 'to watch movies': 10,\n",
              " 'too mary also': 11,\n",
              " 'watch football games': 12,\n",
              " 'watch movies mary': 13}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arzpa1l5V9Pc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBftudgA6J6n"
      },
      "source": [
        "**CountVectorizer Unigrams and Bi-grams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JAcqWRn_gD-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "outputId": "7d927005-aecb-44cf-8b36-d5e703a62109"
      },
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
        "X = vectorizer.fit_transform(text)\n",
        "pd.DataFrame(X.toarray(),index=text,columns=vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>also</th>\n",
              "      <th>also likes</th>\n",
              "      <th>football</th>\n",
              "      <th>football games</th>\n",
              "      <th>games</th>\n",
              "      <th>likes</th>\n",
              "      <th>likes movies</th>\n",
              "      <th>likes to</th>\n",
              "      <th>mary</th>\n",
              "      <th>mary also</th>\n",
              "      <th>mary likes</th>\n",
              "      <th>movies</th>\n",
              "      <th>movies mary</th>\n",
              "      <th>movies too</th>\n",
              "      <th>paul</th>\n",
              "      <th>paul also</th>\n",
              "      <th>paul likes</th>\n",
              "      <th>to</th>\n",
              "      <th>to watch</th>\n",
              "      <th>too</th>\n",
              "      <th>too mary</th>\n",
              "      <th>watch</th>\n",
              "      <th>watch football</th>\n",
              "      <th>watch movies</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Paul likes to watch movies. Mary likes movies too.</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paul also likes to watch football games</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paul likes to watch movies. Mary likes movies too. Mary also likes to watch football games.</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    also  ...  watch movies\n",
              "Paul likes to watch movies. Mary likes movies too.     0  ...             1\n",
              "Paul also likes to watch football games                1  ...             0\n",
              "Paul likes to watch movies. Mary likes movies t...     1  ...             1\n",
              "\n",
              "[3 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf6MZa3fWE9Q",
        "outputId": "767a60da-dbc8-4235-879e-ab55d2cfe030"
      },
      "source": [
        "vectorizer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'also': 0,\n",
              " 'also likes': 1,\n",
              " 'football': 2,\n",
              " 'football games': 3,\n",
              " 'games': 4,\n",
              " 'likes': 5,\n",
              " 'likes movies': 6,\n",
              " 'likes to': 7,\n",
              " 'mary': 8,\n",
              " 'mary also': 9,\n",
              " 'mary likes': 10,\n",
              " 'movies': 11,\n",
              " 'movies mary': 12,\n",
              " 'movies too': 13,\n",
              " 'paul': 14,\n",
              " 'paul also': 15,\n",
              " 'paul likes': 16,\n",
              " 'to': 17,\n",
              " 'to watch': 18,\n",
              " 'too': 19,\n",
              " 'too mary': 20,\n",
              " 'watch': 21,\n",
              " 'watch football': 22,\n",
              " 'watch movies': 23}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIOJYGWwWFAK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HMF8W4F6USy"
      },
      "source": [
        "**CountVectorizer Unigrams, Bi-grams and Tri-grams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "jbMwjthXAh93",
        "outputId": "e3832d42-f12e-4efe-9711-d7287a3e0756"
      },
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
        "X = vectorizer.fit_transform(text)\n",
        "pd.DataFrame(X.toarray(),index=text,columns=vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>also</th>\n",
              "      <th>also likes</th>\n",
              "      <th>also likes to</th>\n",
              "      <th>football</th>\n",
              "      <th>football games</th>\n",
              "      <th>games</th>\n",
              "      <th>likes</th>\n",
              "      <th>likes movies</th>\n",
              "      <th>likes movies too</th>\n",
              "      <th>likes to</th>\n",
              "      <th>likes to watch</th>\n",
              "      <th>mary</th>\n",
              "      <th>mary also</th>\n",
              "      <th>mary also likes</th>\n",
              "      <th>mary likes</th>\n",
              "      <th>mary likes movies</th>\n",
              "      <th>movies</th>\n",
              "      <th>movies mary</th>\n",
              "      <th>movies mary likes</th>\n",
              "      <th>movies too</th>\n",
              "      <th>movies too mary</th>\n",
              "      <th>paul</th>\n",
              "      <th>paul also</th>\n",
              "      <th>paul also likes</th>\n",
              "      <th>paul likes</th>\n",
              "      <th>paul likes to</th>\n",
              "      <th>to</th>\n",
              "      <th>to watch</th>\n",
              "      <th>to watch football</th>\n",
              "      <th>to watch movies</th>\n",
              "      <th>too</th>\n",
              "      <th>too mary</th>\n",
              "      <th>too mary also</th>\n",
              "      <th>watch</th>\n",
              "      <th>watch football</th>\n",
              "      <th>watch football games</th>\n",
              "      <th>watch movies</th>\n",
              "      <th>watch movies mary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Paul likes to watch movies. Mary likes movies too.</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paul also likes to watch football games</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paul likes to watch movies. Mary likes movies too. Mary also likes to watch football games.</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    also  ...  watch movies mary\n",
              "Paul likes to watch movies. Mary likes movies too.     0  ...                  1\n",
              "Paul also likes to watch football games                1  ...                  0\n",
              "Paul likes to watch movies. Mary likes movies t...     1  ...                  1\n",
              "\n",
              "[3 rows x 38 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CkbvfLrWKVy",
        "outputId": "036049e4-eb5a-4a52-ab9d-97b201fb5399"
      },
      "source": [
        "vectorizer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'also': 0,\n",
              " 'also likes': 1,\n",
              " 'also likes to': 2,\n",
              " 'football': 3,\n",
              " 'football games': 4,\n",
              " 'games': 5,\n",
              " 'likes': 6,\n",
              " 'likes movies': 7,\n",
              " 'likes movies too': 8,\n",
              " 'likes to': 9,\n",
              " 'likes to watch': 10,\n",
              " 'mary': 11,\n",
              " 'mary also': 12,\n",
              " 'mary also likes': 13,\n",
              " 'mary likes': 14,\n",
              " 'mary likes movies': 15,\n",
              " 'movies': 16,\n",
              " 'movies mary': 17,\n",
              " 'movies mary likes': 18,\n",
              " 'movies too': 19,\n",
              " 'movies too mary': 20,\n",
              " 'paul': 21,\n",
              " 'paul also': 22,\n",
              " 'paul also likes': 23,\n",
              " 'paul likes': 24,\n",
              " 'paul likes to': 25,\n",
              " 'to': 26,\n",
              " 'to watch': 27,\n",
              " 'to watch football': 28,\n",
              " 'to watch movies': 29,\n",
              " 'too': 30,\n",
              " 'too mary': 31,\n",
              " 'too mary also': 32,\n",
              " 'watch': 33,\n",
              " 'watch football': 34,\n",
              " 'watch football games': 35,\n",
              " 'watch movies': 36,\n",
              " 'watch movies mary': 37}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tc3875WWKkG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z25Yy1LG6ZPg"
      },
      "source": [
        "**TfidfVectorizer Unigrams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "swaFNkJHAwxJ",
        "outputId": "d6bda4cc-2e90-40d0-d93b-7bb4d219d398"
      },
      "source": [
        "tfidfvectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
        "X = tfidfvectorizer.fit_transform(text)\n",
        "pd.DataFrame(X.toarray(),index=text,columns=tfidfvectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>also</th>\n",
              "      <th>football</th>\n",
              "      <th>games</th>\n",
              "      <th>likes</th>\n",
              "      <th>mary</th>\n",
              "      <th>movies</th>\n",
              "      <th>paul</th>\n",
              "      <th>to</th>\n",
              "      <th>too</th>\n",
              "      <th>watch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Paul likes to watch movies. Mary likes movies too.</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.485804</td>\n",
              "      <td>0.312781</td>\n",
              "      <td>0.625561</td>\n",
              "      <td>0.242902</td>\n",
              "      <td>0.242902</td>\n",
              "      <td>0.312781</td>\n",
              "      <td>0.242902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paul also likes to watch football games</th>\n",
              "      <td>0.429840</td>\n",
              "      <td>0.429840</td>\n",
              "      <td>0.429840</td>\n",
              "      <td>0.333809</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333809</td>\n",
              "      <td>0.333809</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Paul likes to watch movies. Mary likes movies too. Mary also likes to watch football games.</th>\n",
              "      <td>0.209172</td>\n",
              "      <td>0.209172</td>\n",
              "      <td>0.209172</td>\n",
              "      <td>0.487322</td>\n",
              "      <td>0.418344</td>\n",
              "      <td>0.418344</td>\n",
              "      <td>0.162441</td>\n",
              "      <td>0.324881</td>\n",
              "      <td>0.209172</td>\n",
              "      <td>0.324881</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        also  ...     watch\n",
              "Paul likes to watch movies. Mary likes movies too.  0.000000  ...  0.242902\n",
              "Paul also likes to watch football games             0.429840  ...  0.333809\n",
              "Paul likes to watch movies. Mary likes movies t...  0.209172  ...  0.324881\n",
              "\n",
              "[3 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1gZnSTBA04M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfsvHWX2zfZW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W2HM5FIzgel"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iIm3twezhd-"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISbHpHxl29Ke",
        "outputId": "79305741-88a7-4efc-bdc5-6b1e0a7b2d69"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8_9jaEw39WI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dfd8c43-6bd9-4135-c58f-1efde76d8f7e"
      },
      "source": [
        "review = '''At this point I'm sure all these positive reviews are bots paid for. There's no other explanation.\r\n",
        "This movie is absolutely unwatchable. One of the dullest pieces of cinema ever made since... well,\r\n",
        "since Scorcese's Silence (2016). I honestly do not have the faintest idea how anybody can enjoy this crap. Am I in a parallel reality?'''\r\n",
        "print(review)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At this point I'm sure all these positive reviews are bots paid for. There's no other explanation.\n",
            "This movie is absolutely unwatchable. One of the dullest pieces of cinema ever made since... well,\n",
            "since Scorcese's Silence (2016). I honestly do not have the faintest idea how anybody can enjoy this crap. Am I in a parallel reality?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnpY-Nic9kIB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL2cdFUm6rcP"
      },
      "source": [
        "**Tokenization**\r\n",
        "\r\n",
        "It is a method in which sentences are converted into words.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESUvZLeR29Yz",
        "outputId": "1493a5f7-1fd7-48c1-b31a-719a86b708f9"
      },
      "source": [
        "import nltk\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "token = word_tokenize(review)\r\n",
        "print(token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['At', 'this', 'point', 'I', \"'m\", 'sure', 'all', 'these', 'positive', 'reviews', 'are', 'bots', 'paid', 'for', '.', 'There', \"'s\", 'no', 'other', 'explanation', '.', 'This', 'movie', 'is', 'absolutely', 'unwatchable', '.', 'One', 'of', 'the', 'dullest', 'pieces', 'of', 'cinema', 'ever', 'made', 'since', '...', 'well', ',', 'since', 'Scorcese', \"'s\", 'Silence', '(', '2016', ')', '.', 'I', 'honestly', 'do', 'not', 'have', 'the', 'faintest', 'idea', 'how', 'anybody', 'can', 'enjoy', 'this', 'crap', '.', 'Am', 'I', 'in', 'a', 'parallel', 'reality', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTcVmwgz3cES"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vecd0id69rg"
      },
      "source": [
        "**Lowercasing**\r\n",
        "\r\n",
        "the tokenized words into lower case format. (NLU -> nlu). Words having the same meaning like nlp and NLP if they are not converted into lowercase then these both will constitute as non-identical words in the vector space model.\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pdvxTFK38FS",
        "outputId": "e5e3a459-7ec2-4501-edb3-719dcd14ebd6"
      },
      "source": [
        "print(\"Review before lowercasing: \")\r\n",
        "print(review)\r\n",
        "print(\"\")\r\n",
        "print(\"\")\r\n",
        "review_ = ' '.join([word.lower() for word in review.split()])\r\n",
        "text = review_\r\n",
        "print(\"Review after lowercasing: \")\r\n",
        "print(review_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review before lowercasing: \n",
            "At this point I'm sure all these positive reviews are bots paid for. There's no other explanation.\n",
            "This movie is absolutely unwatchable. One of the dullest pieces of cinema ever made since... well,\n",
            "since Scorcese's Silence (2016). I honestly do not have the faintest idea how anybody can enjoy this crap. Am I in a parallel reality?\n",
            "\n",
            "\n",
            "Review after lowercasing: \n",
            "at this point i'm sure all these positive reviews are bots paid for. there's no other explanation. this movie is absolutely unwatchable. one of the dullest pieces of cinema ever made since... well, since scorcese's silence (2016). i honestly do not have the faintest idea how anybody can enjoy this crap. am i in a parallel reality?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDMXFz3938O8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADX2dQ4F7peI"
      },
      "source": [
        "**Stop words removal**\r\n",
        "\r\n",
        "These are the most often used that do not have any significance while determining the two different documents like (a, an, the, etc.) so they are to be removed. Check the below image where from the sentence “Introduction to Natural Language Processing” the “to” word is removed.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTOceL0U7pxL",
        "outputId": "a0eb4580-7fcf-40a2-960c-567833f0a9d0"
      },
      "source": [
        "from nltk.corpus import stopwords\r\n",
        "stop_words = stopwords.words('english')\r\n",
        "from string import punctuation\r\n",
        "punct = list(punctuation)\r\n",
        "tokens = word_tokenize(text)\r\n",
        "print(\"Review before removing stop-words: \")\r\n",
        "print(text)\r\n",
        "print(\"Number of tokens before removing stop-words\", len(tokens))\r\n",
        "print(\"\")\r\n",
        "print(\"\")\r\n",
        "cleaned_review = ' '.join([word for word in text.split() if word not in stop_words])\r\n",
        "print(\"Review after removing stop-words: \")\r\n",
        "print(cleaned_review)\r\n",
        "print(\"Number of tokens after removing stop-words\", len(cleaned_review.split()))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review before removing stop-words: \n",
            "at this point i'm sure all these positive reviews are bots paid for. there's no other explanation. this movie is absolutely unwatchable. one of the dullest pieces of cinema ever made since... well, since scorcese's silence (2016). i honestly do not have the faintest idea how anybody can enjoy this crap. am i in a parallel reality?\n",
            "Number of tokens before removing stop-words 70\n",
            "\n",
            "\n",
            "Review after removing stop-words: \n",
            "point i'm sure positive reviews bots paid for. there's explanation. movie absolutely unwatchable. one dullest pieces cinema ever made since... well, since scorcese's silence (2016). honestly faintest idea anybody enjoy crap. parallel reality?\n",
            "Number of tokens after removing stop-words 33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlzcmlmy7qA0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eStDjeoZ7ScW"
      },
      "source": [
        "**Stemming**\r\n",
        "\r\n",
        "Stemming is a process of reducing words to their word stem, base or root form (for example, books — book, looked — look).\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjJC9O30zflM",
        "outputId": "9a2afecb-5681-4daf-ea60-c5f8ca5f7320"
      },
      "source": [
        "from nltk.stem import PorterStemmer\r\n",
        "ps = PorterStemmer()\r\n",
        "print(\"Review before stemming: \")\r\n",
        "print(cleaned_review)\r\n",
        "print(\"\")\r\n",
        "print(\"\")\r\n",
        "stemmed_review = \" \".join([ps.stem(word) for word in cleaned_review.split()])\r\n",
        "print(\"Review after stemming: \")\r\n",
        "print(stemmed_review)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review before stemming: \n",
            "point i'm sure positive reviews bots paid for. there's explanation. movie absolutely unwatchable. one dullest pieces cinema ever made since... well, since scorcese's silence (2016). honestly faintest idea anybody enjoy crap. parallel reality?\n",
            "\n",
            "\n",
            "Review after stemming: \n",
            "point i'm sure posit review bot paid for. there' explanation. movi absolut unwatchable. one dullest piec cinema ever made since... well, sinc scorcese' silenc (2016). honestli faintest idea anybodi enjoy crap. parallel reality?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGvfVoIOzftr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOW-yM_EnZQn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u4PCcvknbMx"
      },
      "source": [
        "**Numbers removing**\r\n",
        "\r\n",
        "Remove numbers if they are not relevant to your analyses. Usually, regular expressions are used to remove numbers.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnoijxQ1mkDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1618ec80-eeb5-40ad-99f0-1a586a9a2259"
      },
      "source": [
        "import re\r\n",
        "\r\n",
        "print(\"Review before removing numbers: \")\r\n",
        "print(stemmed_review)\r\n",
        "print(\"\")\r\n",
        "print(\"\")\r\n",
        "cleaned_review_ = re.sub(r'\\d+', '', stemmed_review)\r\n",
        "print(\"Review after removing numbers: \")\r\n",
        "print(cleaned_review_)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review before removing numbers: \n",
            "point i'm sure posit review bot paid for. there' explanation. movi absolut unwatchable. one dullest piec cinema ever made since... well, sinc scorcese' silenc (2016). honestli faintest idea anybodi enjoy crap. parallel reality?\n",
            "\n",
            "\n",
            "Review after removing numbers: \n",
            "point i'm sure posit review bot paid for. there' explanation. movi absolut unwatchable. one dullest piec cinema ever made since... well, sinc scorcese' silenc (). honestli faintest idea anybodi enjoy crap. parallel reality?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPCXnyqQmjgR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H0Bj9SxnkKL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egEnPhb4nkaH"
      },
      "source": [
        "**Remove punctuation**\r\n",
        "\r\n",
        "The following code removes this set of symbols [!”#$%&’()*+,-./:;<=>?@[\\]^_`{|}~]:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhB5ZaQtnwyB",
        "outputId": "453b6839-c572-4fc1-b14c-15e14b7e08de"
      },
      "source": [
        "import string\r\n",
        "\r\n",
        "print(\"Review before removing punctuation: \")\r\n",
        "print(cleaned_review_)\r\n",
        "print(\"\")\r\n",
        "print(\"\")\r\n",
        "cleaned_review__ = cleaned_review_.translate(str.maketrans('', '', string.punctuation))\r\n",
        "print(\"Review after removing punctuation: \")\r\n",
        "print(cleaned_review__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review before removing punctuation: \n",
            "point i'm sure posit review bot paid for. there' explanation. movi absolut unwatchable. one dullest piec cinema ever made since... well, sinc scorcese' silenc (). honestli faintest idea anybodi enjoy crap. parallel reality?\n",
            "\n",
            "\n",
            "Review after removing punctuation: \n",
            "point im sure posit review bot paid for there explanation movi absolut unwatchable one dullest piec cinema ever made since well sinc scorcese silenc  honestli faintest idea anybodi enjoy crap parallel reality\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh8m-kOUozuh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD-yV4A3DxbU"
      },
      "source": [
        "# **Sentiment Analysis with Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMuOCtR3ERxW"
      },
      "source": [
        "**Import data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0OhCbV4mkRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da923898-03d2-4690-a909-c5038a144a36"
      },
      "source": [
        "import numpy as np\r\n",
        "from keras.datasets import imdb\r\n",
        "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=None)\r\n",
        "data = np.concatenate((training_data, testing_data), axis=0)\r\n",
        "targets = np.concatenate((training_targets, testing_targets), axis=0)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "decoded = []\r\n",
        "index = imdb.get_word_index()\r\n",
        "reverse_index = dict([(value, key) for (key, value) in index.items()]) \r\n",
        "for i in range(50000):\r\n",
        "  decoded.append(\" \".join( [reverse_index.get(j - 3, \"#\") for j in data[i]] ))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKGvfFZETxjs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "b66f1a0f-92ac-4aec-ba11-8f11de457439"
      },
      "source": [
        "decoded[100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"# i am a great fan of david lynch and have everything that he's made on dvd except for hotel room the 2 hour twin peaks movie so when i found out about this i immediately grabbed it and and what is this it's a bunch of crudely drawn black and white cartoons that are loud and foul mouthed and unfunny maybe i don't know what's good but maybe this is just a bunch of crap that was foisted on the public under the name of david lynch to make a few bucks too let me make it clear that i didn't care about the foul language part but had to keep adjusting the sound because my neighbors might have all in all this is a highly disappointing release and may well have just been left in the deluxe box set as a curiosity i highly recommend you don't spend your money on this 2 out of 10\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5z3JTf2Bs2i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mls8Oz4CEWcn"
      },
      "source": [
        "**Preprocessing** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1SzNNSiBs9d",
        "outputId": "ab7a977a-129c-40df-a9d4-dfc108a5b2d8"
      },
      "source": [
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem.porter import PorterStemmer\r\n",
        "from wordcloud import WordCloud,STOPWORDS\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import spacy\r\n",
        "import re,string,unicodedata\r\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\r\n",
        "from nltk.stem import LancasterStemmer,WordNetLemmatizer\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "majZM_6Ee8iV"
      },
      "source": [
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ_QyIaBCest"
      },
      "source": [
        "\r\n",
        "#Tokenization of text\r\n",
        "tokenizer=ToktokTokenizer()\r\n",
        "\r\n",
        "#Setting English stopwords\r\n",
        "stopword_list=nltk.corpus.stopwords.words('english')\r\n",
        "\r\n",
        "#Removing the html strips\r\n",
        "def strip_html(text):\r\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\r\n",
        "    return soup.get_text()\r\n",
        "\r\n",
        "#Removing the square brackets\r\n",
        "def remove_between_square_brackets(text):\r\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\r\n",
        "\r\n",
        "#Removing the noisy text\r\n",
        "def denoise_text(text):\r\n",
        "    text = strip_html(text)\r\n",
        "    text = remove_between_square_brackets(text)\r\n",
        "    return text\r\n",
        "\r\n",
        "#Apply function on review column\r\n",
        "IMdB_reviews = []\r\n",
        "for i in decoded:\r\n",
        "  IMdB_reviews.append(denoise_text(i))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4UODxyOe_Az"
      },
      "source": [
        "#Define function for removing special characters\r\n",
        "def remove_special_characters(text, remove_digits=True):\r\n",
        "    #pattern=r'[^a-zA-z0-9\\s]'\r\n",
        "    pattern=r'[^a-zA-z\\s]'\r\n",
        "    text=re.sub(pattern,'',text)\r\n",
        "    return text\r\n",
        "\r\n",
        "#Apply function on review column\r\n",
        "IMdB_reviews_1 = []\r\n",
        "for i in IMdB_reviews:\r\n",
        "  IMdB_reviews_1.append(remove_special_characters(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prnXNPb1fE0i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "c7776b4e-ee3d-4d1d-b787-fcb624da9908"
      },
      "source": [
        "IMdB_reviews_1[100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' i am a great fan of david lynch and have everything that hes made on dvd except for hotel room the  hour twin peaks movie so when i found out about this i immediately grabbed it and and what is this its a bunch of crudely drawn black and white cartoons that are loud and foul mouthed and unfunny maybe i dont know whats good but maybe this is just a bunch of crap that was foisted on the public under the name of david lynch to make a few bucks too let me make it clear that i didnt care about the foul language part but had to keep adjusting the sound because my neighbors might have all in all this is a highly disappointing release and may well have just been left in the deluxe box set as a curiosity i highly recommend you dont spend your money on this  out of '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsysWInvDVdT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMiPR14uD4s-"
      },
      "source": [
        "#Stemming the text\r\n",
        "def simple_stemmer(text):\r\n",
        "    ps=nltk.porter.PorterStemmer()\r\n",
        "    text= ' '.join([ps.stem(word) for word in text.split()])\r\n",
        "    return text\r\n",
        "\r\n",
        "#Apply function on review column\r\n",
        "IMdB_reviews_cleaned = []\r\n",
        "for i in IMdB_reviews_1:\r\n",
        "  IMdB_reviews_cleaned.append(simple_stemmer(i))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2fhyimSEIa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "0d9517bd-849d-48c5-b483-33384cec63ad"
      },
      "source": [
        "IMdB_reviews_cleaned[100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i am a great fan of david lynch and have everyth that he made on dvd except for hotel room the hour twin peak movi so when i found out about thi i immedi grab it and and what is thi it a bunch of crude drawn black and white cartoon that are loud and foul mouth and unfunni mayb i dont know what good but mayb thi is just a bunch of crap that wa foist on the public under the name of david lynch to make a few buck too let me make it clear that i didnt care about the foul languag part but had to keep adjust the sound becaus my neighbor might have all in all thi is a highli disappoint releas and may well have just been left in the delux box set as a curios i highli recommend you dont spend your money on thi out of'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpAXDt11EONQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDbRUu5xE0O5"
      },
      "source": [
        "**Split data to train set and test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9YQFNyOE5eS"
      },
      "source": [
        "test_x = IMdB_reviews_cleaned[:10000]\r\n",
        "test_y = targets[:10000]\r\n",
        "train_x = IMdB_reviews_cleaned[10000:]\r\n",
        "train_y = targets[10000:]\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UJerXgDFXG_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTeLfdhAFZ-Q"
      },
      "source": [
        "**Apply CountVectorizer with Unigrams for train and test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gawqpn1kFkhj",
        "outputId": "538907df-ac20-41eb-df73-ea21d13deb11"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "\r\n",
        "vectorizer = CountVectorizer()\r\n",
        "X_train = vectorizer.fit_transform(train_x)\r\n",
        "print(\"Feature Matrix dimension of training set: \", X_train.shape )\r\n",
        "#X_train = X_train.toarray()\r\n",
        "\r\n",
        "X_test = vectorizer.transform(test_x)\r\n",
        "print(\"Feature Matrix dimension of test set: \", X_test.shape )\r\n",
        "#X_test = X_test.toarray()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Matrix dimension of training set:  (40000, 43194)\n",
            "Feature Matrix dimension of test set:  (10000, 43194)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT1C-BKOFwnh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbzF2uvsKNQy"
      },
      "source": [
        "**Train and test the model using LogisticRegression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXh_AZr-Fz0v",
        "outputId": "20db3f6b-f446-42ab-8649-459166c09885"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "lg = LogisticRegression()\r\n",
        "lg.fit(X_train, train_y)\r\n",
        "prediction = lg.predict(X_test)\r\n",
        "print(classification_report(prediction, test_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.88      4897\n",
            "           1       0.89      0.88      0.88      5103\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86aFPBT6Ki4G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Erb-j9fh6LXJ"
      },
      "source": [
        "**Manipulations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37bmKFYfNv2A",
        "outputId": "5557fe71-0a38-47ab-b93e-85021ca9fb19"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "\r\n",
        "vectorizer = CountVectorizer(ngram_range = (1, 2))\r\n",
        "X_train = vectorizer.fit_transform(train_x)\r\n",
        "print(\"Feature Matrix dimension of training set: \", X_train.shape )\r\n",
        "#X_train = X_train.toarray()\r\n",
        "\r\n",
        "X_test = vectorizer.transform(test_x)\r\n",
        "print(\"Feature Matrix dimension of test set: \", X_test.shape )\r\n",
        "#X_test = X_test.toarray()\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "lg = LogisticRegression()\r\n",
        "lg.fit(X_train, train_y)\r\n",
        "prediction = lg.predict(X_test)\r\n",
        "print(classification_report(prediction, test_y))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Matrix dimension of training set:  (40000, 1659945)\n",
            "Feature Matrix dimension of test set:  (10000, 1659945)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.91      0.90      4892\n",
            "           1       0.91      0.90      0.90      5108\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe-fQjSXOBTL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR7l6p3l6szT",
        "outputId": "2d962730-92be-4088-b1d8-5e391cac2668"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "\r\n",
        "vectorizer = TfidfVectorizer(ngram_range = (1, 1))\r\n",
        "X_train = vectorizer.fit_transform(train_x)\r\n",
        "print(\"Feature Matrix dimension of training set: \", X_train.shape )\r\n",
        "#X_train = X_train.toarray()\r\n",
        "\r\n",
        "X_test = vectorizer.transform(test_x)\r\n",
        "print(\"Feature Matrix dimension of test set: \", X_test.shape )\r\n",
        "#X_test = X_test.toarray()\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "lg = LogisticRegression()\r\n",
        "lg.fit(X_train, train_y)\r\n",
        "prediction = lg.predict(X_test)\r\n",
        "print(classification_report(prediction, test_y))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Matrix dimension of training set:  (40000, 43194)\n",
            "Feature Matrix dimension of test set:  (10000, 43194)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.90      0.89      4842\n",
            "           1       0.90      0.89      0.89      5158\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwJ1tlx96zQK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AooStD3V6-Yc",
        "outputId": "740b18cb-5585-46b2-a4be-1da42bfa5d7a"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "\r\n",
        "vectorizer = TfidfVectorizer(ngram_range = (1, 2))\r\n",
        "X_train = vectorizer.fit_transform(train_x)\r\n",
        "print(\"Feature Matrix dimension of training set: \", X_train.shape )\r\n",
        "#X_train = X_train.toarray()\r\n",
        "\r\n",
        "X_test = vectorizer.transform(test_x)\r\n",
        "print(\"Feature Matrix dimension of test set: \", X_test.shape )\r\n",
        "#X_test = X_test.toarray()\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "lg = LogisticRegression()\r\n",
        "lg.fit(X_train, train_y)\r\n",
        "prediction = lg.predict(X_test)\r\n",
        "print(classification_report(prediction, test_y))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Matrix dimension of training set:  (40000, 1659945)\n",
            "Feature Matrix dimension of test set:  (10000, 1659945)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.91      0.89      4818\n",
            "           1       0.91      0.89      0.90      5182\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTD2Q1Dz7ak_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO1AFC_w7ats"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z34MzLT86_dX",
        "outputId": "e01cec62-9484-4baa-cbf7-60d1f1b2ba4d"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "\r\n",
        "vectorizer = TfidfVectorizer(ngram_range = (2, 2))\r\n",
        "X_train = vectorizer.fit_transform(train_x)\r\n",
        "print(\"Feature Matrix dimension of training set: \", X_train.shape )\r\n",
        "#X_train = X_train.toarray()\r\n",
        "\r\n",
        "X_test = vectorizer.transform(test_x)\r\n",
        "print(\"Feature Matrix dimension of test set: \", X_test.shape )\r\n",
        "#X_test = X_test.toarray()\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "lg = LogisticRegression()\r\n",
        "lg.fit(X_train, train_y)\r\n",
        "prediction = lg.predict(X_test)\r\n",
        "print(classification_report(prediction, test_y))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Matrix dimension of training set:  (40000, 1616751)\n",
            "Feature Matrix dimension of test set:  (10000, 1616751)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.89      4814\n",
            "           1       0.90      0.88      0.89      5186\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2feX3JZ7bjG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vcpnfky370Bs",
        "outputId": "240d876b-4c75-45db-ea34-0b8e69ef8f3c"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "\r\n",
        "vectorizer = TfidfVectorizer(ngram_range = (1, 1))\r\n",
        "X_train = vectorizer.fit_transform(train_x)\r\n",
        "print(\"Feature Matrix dimension of training set: \", X_train.shape )\r\n",
        "#X_train = X_train.toarray()\r\n",
        "\r\n",
        "X_test = vectorizer.transform(test_x)\r\n",
        "print(\"Feature Matrix dimension of test set: \", X_test.shape )\r\n",
        "#X_test = X_test.toarray()\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "lsvm = LinearSVC()\r\n",
        "lsvm.fit(X_train, train_y)\r\n",
        "prediction = lsvm.predict(X_test)\r\n",
        "print(classification_report(prediction, test_y))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Matrix dimension of training set:  (40000, 43194)\n",
            "Feature Matrix dimension of test set:  (10000, 43194)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.89      4894\n",
            "           1       0.90      0.89      0.89      5106\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Uzkv3EY79zm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUNT3X8Dr0zA",
        "outputId": "ae40efbd-d2d0-4e24-f479-5a9fdae681c9"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "\r\n",
        "vectorizer = TfidfVectorizer(ngram_range = (1, 2))\r\n",
        "X_train = vectorizer.fit_transform(train_x)\r\n",
        "print(\"Feature Matrix dimension of training set: \", X_train.shape )\r\n",
        "#X_train = X_train.toarray()\r\n",
        "\r\n",
        "X_test = vectorizer.transform(test_x)\r\n",
        "print(\"Feature Matrix dimension of test set: \", X_test.shape )\r\n",
        "#X_test = X_test.toarray()\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "lsvm = LinearSVC()\r\n",
        "lsvm.fit(X_train, train_y)\r\n",
        "prediction = lsvm.predict(X_test)\r\n",
        "print(classification_report(prediction, test_y))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Matrix dimension of training set:  (40000, 1659945)\n",
            "Feature Matrix dimension of test set:  (10000, 1659945)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.92      0.91      4858\n",
            "           1       0.92      0.91      0.91      5142\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFIItaIhr2DP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe5a9s5xsk59",
        "outputId": "387e609a-d781-4cad-ab4a-55b258686d36"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "\r\n",
        "vectorizer = TfidfVectorizer(ngram_range = (2, 3))\r\n",
        "X_train = vectorizer.fit_transform(train_x)\r\n",
        "print(\"Feature Matrix dimension of training set: \", X_train.shape )\r\n",
        "#X_train = X_train.toarray()\r\n",
        "\r\n",
        "X_test = vectorizer.transform(test_x)\r\n",
        "print(\"Feature Matrix dimension of test set: \", X_test.shape )\r\n",
        "#X_test = X_test.toarray()\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "lsvm = LinearSVC()\r\n",
        "lsvm.fit(X_train, train_y)\r\n",
        "prediction = lsvm.predict(X_test)\r\n",
        "print(classification_report(prediction, test_y))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Matrix dimension of training set:  (40000, 6680196)\n",
            "Feature Matrix dimension of test set:  (10000, 6680196)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.91      0.90      4789\n",
            "           1       0.92      0.89      0.90      5211\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVS2JMMjsmNC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3mPB4iVudZS",
        "outputId": "f3673e4a-b72b-4d56-cf99-a77224865e9f"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "\r\n",
        "vectorizer = TfidfVectorizer(ngram_range = (1, 4))\r\n",
        "X_train = vectorizer.fit_transform(train_x)\r\n",
        "print(\"Feature Matrix dimension of training set: \", X_train.shape )\r\n",
        "#X_train = X_train.toarray()\r\n",
        "\r\n",
        "X_test = vectorizer.transform(test_x)\r\n",
        "print(\"Feature Matrix dimension of test set: \", X_test.shape )\r\n",
        "#X_test = X_test.toarray()\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "lsvm = LinearSVC()\r\n",
        "lsvm.fit(X_train, train_y)\r\n",
        "prediction = lsvm.predict(X_test)\r\n",
        "print(classification_report(prediction, test_y))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Matrix dimension of training set:  (40000, 14112910)\n",
            "Feature Matrix dimension of test set:  (10000, 14112910)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.92      0.90      4816\n",
            "           1       0.92      0.90      0.91      5184\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWHWir59un0N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c42073-9c02-491d-f144-e3bdf4a79670"
      },
      "source": [
        "\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "\r\n",
        "vectorizer = TfidfVectorizer(ngram_range = (1, 1))\r\n",
        "X_train = vectorizer.fit_transform(train_x)\r\n",
        "print(\"Feature Matrix dimension of training set: \", X_train.shape )\r\n",
        "#X_train = X_train.toarray()\r\n",
        "\r\n",
        "X_test = vectorizer.transform(test_x)\r\n",
        "print(\"Feature Matrix dimension of test set: \", X_test.shape )\r\n",
        "#X_test = X_test.toarray()\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "nb = MultinomialNB()\r\n",
        "nb.fit(X_train, train_y)\r\n",
        "prediction = nb.predict(X_test)\r\n",
        "print(classification_report(prediction, test_y))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Matrix dimension of training set:  (40000, 43194)\n",
            "Feature Matrix dimension of test set:  (10000, 43194)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.84      0.85      5069\n",
            "           1       0.84      0.86      0.85      4931\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DbUTW1pOtP1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}